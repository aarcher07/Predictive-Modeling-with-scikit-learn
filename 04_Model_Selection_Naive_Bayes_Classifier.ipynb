{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Review \n",
    "\n",
    "## 0.A Scikit-Learn\n",
    "\n",
    "Scikit-Learn is a machine learning python package. It allows users to access machine learning algorithms via **object-oriented programming**.\n",
    "\n",
    "## 0.B Data Set\n",
    "\n",
    "I will be using a dataset of antibiotic resistance in bacteria strains. \n",
    "\n",
    "- Each bacteria is labeled with its resistance to the antibiotic, azithromycin.\n",
    "- Additionally, each bacteria sample is labelled if its genome contains certain strands of DNA.\n",
    "\n",
    "We would like to learn antibiotic resistance from the bacterial genome.\n",
    "\n",
    "- Our predictors are whether strands of DNA are present.\n",
    "- Our response are resistance classes.\n",
    "\n",
    "\n",
    "## 0.C Data Preprocessing\n",
    "\n",
    "We did a bit of data preprocessing: \n",
    "\n",
    "- encoded the resistance feature as 0 - \"resistant,\" 1 - \"susceptible\".\n",
    "- encoded all features of the DNA strands as , 0 - \"if its genome does not contain the strand of DNA\", 1 - \"if its genome contains the strand of DNA.\"\n",
    "- did a 70:30 training-test split\n",
    "\n",
    "\n",
    "## 0.D Trained Model: Gaussian Naive Bayes\n",
    "\n",
    "Before, we use a Gaussian Naive Bayes algorithm to learn a classifier of antibiotic resistance in the bacteria. I run the code to create the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load training data\n",
    "labels_training_set = pd.read_csv('datasets/labels_training_set',index_col=0)\n",
    "DNA_training_set = pd.read_csv('datasets/DNA_training_set',index_col=0)\n",
    "\n",
    "#load test data\n",
    "\n",
    "labels_test_set = pd.read_csv('datasets/labels_test_set',index_col=0)\n",
    "DNA_test_set = pd.read_csv('datasets/DNA_test_set',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#instantiate a Naive Bayes classifier \n",
    "gNB = GaussianNB()\n",
    "\n",
    "#learn classifier from data \n",
    "gNB.fit(DNA_training_set,labels_training_set.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.D Model Evaluation: Guassian Naive Bayes\n",
    "\n",
    "Then, we evaluated the Gaussian Naive Bayes classifier on the test data and found that the model has an accuracy of $88\\%$. \n",
    "\n",
    "**In this section, we will be exploring ways of improving model accuracy and comparing classifiers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Improvement: Bernoulli Naive Bayes\n",
    "\n",
    "## 4.A Gaussian Naive Bayes is not correct\n",
    "\n",
    "Recall that Gaussian Naive Bayes assumes the probability that a feature is 0 or 1 is Gaussian. \n",
    "\n",
    "<img src=\"images/02_gNB_05.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the value of a feature follows a Gaussian distribution, the feature is allowed to take on any numerical value! \n",
    "\n",
    "This is not right. Recall what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# print head of training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanatory variable is only allowed to take on values: 0's or 1's. Gaussian assumption of feature is wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.B Bernoulli Naive Bayes\n",
    "\n",
    "We need an assumption on our explanatory variables that will restrict them to 0 or 1. This can be done if we assume that features follow a Bernoulli distribution. A Bernoulli distribution restricts variables to assume a value of 0 or 1. \n",
    "\n",
    "<img src=\"images/04_Bernoulli_Naive_Bayes.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "Luckily, there is an implementation of Bernoulli Naive Bayes in ```sklearn```.\n",
    "\n",
    "*Note: that $p$ values seen here are different from $p$ values in hypothesis testing.*  $p$ value of Bernoulli distribution is the probability of taking the value $1$. A Bernoulli distribution can be thought of as getting heads or tails on a weighted coin. Whereas, $p$ values in hypothesis testing is the probability of making a type 1 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#instantiate a Naive Bayes classifier \n",
    "\n",
    "#train classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B.1 $p$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab the $p$ values for each feature per class. However, BernoulliNB stores the log of $p$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature_log_prob_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the $p$ values, we take the exponential of ```bNB.feature_log_prob_```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the information better as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.exp(bNB.feature_log_prob_),\n",
    "             columns=DNA_training_set.columns,\n",
    "             index=['Resistant','Susceptible'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.C Evaluating Bernoulli Naive Bayes Classifier\n",
    "\n",
    "### Exercise 4.C.1: Confusion Matrix and Score Bernoulli Naive Bayes Classifier\n",
    "\n",
    "Recall that we used a confusion matrix and the score function to evaluate the accuracy of the Gaussian Naive Bayes classifier.  *Now, we will do the same for a Bernoulli Naive Bayes classifier.*\n",
    "\n",
    "- We generated the confusion matrix using code:\n",
    "\n",
    "```\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(gNB.predict(DNA_test_set),labels_test_set)\n",
    "\n",
    "confusionMatrix_df = pd.DataFrame(confusionMatrix,\n",
    "                                  columns=['Predicted: 0' , 'Predicted: 1'],\n",
    "                                  index=['Actual: 0' , 'Actual: 1'])\n",
    "confusionMatrix_df\n",
    "```\n",
    "\n",
    "- We also computed the total fraction of observations correctly classified using the code:\n",
    "\n",
    "```\n",
    "gNB.score(DNA_test_set,labels_test_set)\n",
    "```\n",
    "\n",
    "Edit the code above to test the accuracy of the Bernoulli Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here \n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the Gaussian Naive Bayes classifier, the Bernoulli Naive Bayes classifier appears to be more accurate. The Gaussian Naive Bayes classifier has an accuracy of $88\\%$ while the Bernoulli Naive Bayes classifier has an accuracy of $91\\%.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.C.2 Class probability of a single observation\n",
    "\n",
    "Using the ```predict_proba``` method, we can grab the probability that an observation in the test set belongs in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_observation = DNA_test_set.iloc[[0]]\n",
    "# compute probability that the first observation belongs in resistant or susceptible  class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier predicts that there is a $100\\%$ chance that the observation is in the resistant class. The classifier also predicts that there is a $0\\%$ chance that the observation is in the susceptible class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.C.2: Probability of the tenth observation\n",
    "\n",
    "Using the trained Bernuolli Naive Bayes model, ```bNB```, compute and interpret the probability values of the sectenthond observation in our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n",
    "tenth_observation = DNA_test_set.iloc[[9]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts a $100\\%$ chance that the observation will be resistant and a $0\\%$ chance that the observation will be susceptible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.C.3 Class probability of the entire dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the class probability of the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict prob of DNA_test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better visualized using a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bNB.predict_proba(DNA_test_set),\n",
    "             index=DNA_test_set.index,\n",
    "             columns=['Probability of being resistant','Probability of being susceptible'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.D Comparing Classifiers\n",
    "\n",
    "### 4.D.1 Threshold Values\n",
    "\n",
    "To compare classifiers, we need to take more care. We cannot simply compare total fraction of observations correctly classified.\n",
    "\n",
    "Consider the histogram of probabilities of being in the susceptible class, \n",
    "\n",
    "<img src=\"images/04_histogram_01.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "Classifiers have a threshold probability above which all observations assigned 1 and below which all observations assigned 0. \n",
    "\n",
    "<img src=\"images/04_histogram_02.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Setting a threshold value causes observations to be correctly and incorrectly classified. The threshold value then determines the output of the ```score``` and ```confusion_matrix``` function.\n",
    "\n",
    "To compare classifiers, we determine how the efficacy of the classifiers varies across threshold values.\n",
    "\n",
    "Note: \n",
    "\n",
    "**In the ideal case, there is no overlap of the histograms of probabilities.**\n",
    "\n",
    "**In the worst case, there is complete overlap of histograms of probabilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.D.2 ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are ROC curves?\n",
    "\n",
    "*ROC curves plot how well the probabilities of the susceptible category are separated from the probabilities of resistant category.*\n",
    "\n",
    "\n",
    "#### How do ROC curve work?\n",
    "\n",
    "Recall that cells of the confusion matrix have special names:\n",
    "    \n",
    "\n",
    "| . | Predicted: 0 | Predicted: 1 |\n",
    "| --- | --- | --- |\n",
    "| **Actual: 0** | True Negative (TN) | False Positive  (FP) |\n",
    "| **Actual: 1** | False Negative (FN) | True Positive  (TP) |\n",
    "\n",
    "\n",
    "While varying the threshold value of a classifier, *an ROC curve plots the true positive rates versus false positive rates*. \n",
    "\n",
    "\n",
    "<img src=\"images/04_ROC_curve_example.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "The true and false positive rates are related to the entries of the confusion matrix.\n",
    "\n",
    "\n",
    "$$ \\text{true positive rates} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}= \\text{fraction of susceptible bacteria correctly classified} $$\n",
    "\n",
    "$$ \\text{false positive rates} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} = \\text{fraction of resistant bacteria incorrectly classified}$$\n",
    "\n",
    "\n",
    "#### How do ROC curves detect if the probabilities of a classifier are well separated?\n",
    "\n",
    "##### Best Case: No overlap in histogram of probabilities\n",
    "\n",
    "<img src=\"images/04_best_case_histogram_ROC_I.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/04_best_case_histogram_ROC_II.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/04_best_case_ROC.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "With no overlap in the histograms, the ROC curve\n",
    "\n",
    "- is close to the true positive axis initially and rises to true positive rate of 1\n",
    "- saturates slowly to a false positive rate of 1\n",
    "\n",
    "##### Worst Case: Complete overlap in histogram of probabilities\n",
    "\n",
    "<img src=\"images/04_worst_case_histogram_ROC_I.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/04_worst_case_histogram_ROC_II.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "<img src=\"images/04_worst_case_ROC.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "With complete overlap in the histograms, true positive rate equals the false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating ROC curves using Sklearn\n",
    "\n",
    "To generate the ROC curve, we use the ```roc_curve``` function in ```sklearn.metrics``` module. \n",
    "\n",
    "```roc_curve``` returns the false positive rates and true positive rates of the classifier. It also returns the thresholds used to compute the rates.\n",
    "\n",
    "```roc_curve```  takes as arguments:\n",
    "- the classes of each observation in the test set \n",
    "- and the probability of each observation being in class 1. In this case, class 1 is the susceptible class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#generate false and true positive rates for bNB\n",
    "probability_values_bNB= bNB.predict_proba(DNA_test_set)\n",
    "# compute false and true positive rate using labels_test_set,   probability_values_bNB[:,1]\n",
    "# store as false_positive_rate_bNB, true_positive_rate_bNB, thresholds_bNB \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate false and true positive rates for gNB\n",
    "probability_values_gNB= gNB.predict_proba(DNA_test_set)\n",
    "# compute false and true positive rate using labels_test_set,   probability_values_gNB[:,1]\n",
    "# store as false_positive_rate_gNB, true_positive_rate_gNB, thresholds_gNB \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "lw = 2\n",
    "plt.plot(false_positive_rate_bNB, true_positive_rate_bNB, color='blue' )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* If a classifier has an ROC that falls on the navy line, then that classifier is no better than random. In this case, the classifier cannot determine susceptible category from the resistant category and the probability of the histograms would overlap.\n",
    "\n",
    "If a classifier has an ROC that is above the navy line, then that classifier is better than random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.D.2: Plotting ROC curve of Gaussian Naive Bayes classifier\n",
    "\n",
    "I generated the data to plot the ROC of the Gaussian Naive Bayes classifier.\n",
    "\n",
    "```\n",
    "#generate false and true positive rates for gNB\n",
    "probability_values_gNB= gNB.predict_proba(DNA_test_set)\n",
    "false_positive_rate_gNB, true_positive_rate_gNB, threshold_gNB = roc_curve(DNA_test_set, \n",
    "                                                               probability_values_gNB[:,1])\n",
    "```\n",
    "\n",
    "Modify the code below to plot the ROC of the Gaussian Naive Bayes classifier. Is this classifier better than random?\n",
    "\n",
    "```\n",
    "lw = 2\n",
    "plt.plot(false_positive_rate_bNB, true_positive_rate_bNB, color='green' )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is better than random since the ROC curve is above the navy line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.D.3 Comparing ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curves qualitatively compare classifiers.\n",
    "\n",
    "To compare classifiers quantitatively, we use the area under the curve (AUC) of the ROC curve.\n",
    "\n",
    "#### Best Case\n",
    "\n",
    "In the best case, no overlap in histograms, the plot forms a square and the area is 1.\n",
    "\n",
    "<img src=\"images/04_best_case_ROC.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "#### Worst Case\n",
    "\n",
    "In the worst case, complete overlap in histograms, the plot forms a triangle and the area is 1/2.\n",
    "\n",
    "<img src=\"images/04_worst_case_ROC.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "ROC curves with area closer to 1 are better classifiers. \n",
    "\n",
    "To compute area under the curve, we use the ```auc``` function in the ```sklearn.metrics``` module.\n",
    "\n",
    "```auc``` returns the area under the curve. ```auc``` takes two arguments.\n",
    "- The first argument of ```auc``` is the false positive rate values from ```roc_curve.```  \n",
    "- The second argument of ```auc``` is the true positive rate values from ```roc_curve.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "# generate auc as roc_auc_bNB from false_positive_rate_bNB, true_positive_rate_bNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.D.3: Area under the curve for Gaussian Naive Bayes\n",
    "\n",
    "Using the ```auc``` function, compute the area under the curve for the Gaussian Naive Bayes classifier as ```roc_auc_gNB```. Which classifier is better, Gaussian Naive Bayes or Bernoulli Naive Bayes?   \n",
    "\n",
    "Note: I already calculated ```true_positive_rate_gNB``` and ```false_positive_rate_gNB``` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# enter solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli Naive Bayes classifier is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.D.4 Visualizing the results\n",
    "\n",
    "We can combine the results of sections 4.C.2, ROC plots, and 4.C.3, AUC calculations, into one plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.plot(false_positive_rate_gNB, true_positive_rate_gNB, color='green',\n",
    "         lw=lw, label='Gaussian NB ROC curve (area = %0.2f)' % roc_auc_gNB)\n",
    "plt.plot(false_positive_rate_bNB, true_positive_rate_bNB, color='blue',\n",
    "         lw=lw, label='Bernolli NB ROC curve (area = %0.2f)' % roc_auc_bNB)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Possible Improvements\n",
    "\n",
    "## 5.1 Interactions terms\n",
    "\n",
    "Recall that all Naive Bayes algorithms assume that the value of any feature is independent of any other feature. In our case, the presence of a segment of the genome does not affect the presence of another segment.\n",
    "\n",
    "This assumption is not true. A gene at a given location of the genome can determine a gene at another location. Thus, features are not truly independent. While Naive Bayes classifiers do not allow confounding effects between features, there are classifiers that do.\n",
    "\n",
    "\n",
    "Logistic regression, linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) allow for confounding effects. \n",
    "\n",
    "- However, LDA and QDA assume that the probability that a feature takes on a given value is Gaussian. \n",
    "\n",
    "- Logistic regression does not make assumptions about the probability distribution of a feature. However, you would have to tell logistic regression what interactions to consider. Doing logistic regression with all interaction terms and some penalty, like LASSO, might be suitable.\n",
    "\n",
    "## 5.2 Non-parametric models\n",
    "\n",
    "The methods we discussed so far are all parametric classifiers. Parametric techniques learn parameters, such as mean and variance in the Gaussian Naive Bayes and $p$ values in Bernoulli Naive Bayes. The parameters are used in a formula to compute the probability. \n",
    "\n",
    "There exist non-parametric classifiers. Non-parametric classifiers do not have formulas to calculate the probability that an observation falls into a given class. Non-parametric methods instead use an algorithm to learn the data structure. Non-parametric methods are more flexible than parametric techniques. However, nonparametric methods are sometimes less interpretable than parametric methods.   Given the complexity of this problem, non-parametric classifiers such as classification trees or K-Nearest Neighbour classifiers may be suitable alternatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
