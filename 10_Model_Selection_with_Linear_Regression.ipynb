{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Review\n",
    "## 0.A Scikit-Learn\n",
    "\n",
    "Scikit-Learn is a machine learning python package. It allows users to access machine learning algorithms via **object-oriented programming**.\n",
    "\n",
    "## 0.B Data Set\n",
    "\n",
    "I will be using a dataset of avocado prices.\n",
    "\n",
    "We would like to learn prices of avocado given brand, location sold, total demand, etc.\n",
    "\n",
    "## 0.C Load Data\n",
    "\n",
    "Now, we load our training and test set. Run the code below to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load explanatory variables\n",
    "avocado_training_set  = pd.read_csv(\"datasets/avocado_training_set\",index_col=0)\n",
    "avocado_training_set['year'] = avocado_training_set['year'].astype(str)\n",
    "avocado_training_set['Month'] = avocado_training_set['Month'].astype(str)\n",
    "\n",
    "avocado_test_set = pd.read_csv(\"datasets/avocado_test_set\",index_col=0)\n",
    "avocado_test_set['year'] = avocado_test_set['year'].astype(str)\n",
    "avocado_test_set['Month'] = avocado_test_set['Month'].astype(str)\n",
    "\n",
    "# load predictors\n",
    "prices_training_set = pd.read_csv(\"datasets/avocado_prices_training_set\",index_col=0)\n",
    "prices_test_set = pd.read_csv(\"datasets/avocado_prices_test_set\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we hot-one encoded some categorical variables in the training and test set. In this section, we hot-one encode all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables_ = ['Month','region','type','year']\n",
    "\n",
    "# split all categorical variables for training set\n",
    "avocado_split_ = pd.get_dummies(data=avocado_training_set[categorical_variables_],\n",
    "                                     drop_first=True)\n",
    "avocado_training_set_cleaned = pd.concat([avocado_training_set,avocado_split_], \n",
    "                                     axis=1, sort=False)\n",
    "avocado_training_set_cleaned = avocado_training_set_cleaned.drop(categorical_variables_,axis=1,\n",
    "                                                         inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4046', '4225', '4770', 'Large Bags', 'Small Bags', 'Total Volume',\n",
       "       'XLarge Bags', 'Month_10', 'Month_11', 'Month_12', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_organic', 'year_2016',\n",
       "       'year_2017', 'year_2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avocado_training_set_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables_ = ['Month','region','type','year']\n",
    "\n",
    "# split all categorical variables \n",
    "avocado_split_ = pd.get_dummies(data=avocado_test_set[categorical_variables_],\n",
    "                                     drop_first=True)\n",
    "avocado_test_set_cleaned = pd.concat([avocado_test_set,avocado_split_], \n",
    "                                     axis=1, sort=False)\n",
    "avocado_test_set_cleaned = avocado_test_set_cleaned.drop(categorical_variables_,axis=1,\n",
    "                                                         inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section, we will learning how to certain the most accurate linear regression model using our training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.A Linear Regression\n",
    "\n",
    "2. Then, train a **machine learning model** using **labeled data**\n",
    "\n",
    "    - \"Labeled data\" has been labeled with the outcome\n",
    "    - \"Machine learning model\" learns the relationship between the attributes of the data and its outcome\n",
    "\n",
    "Linear regression assumes that there is a *linear* relationship between the explanatory variables and the outcome. \n",
    "\n",
    "That our case linear regression means that price does up or down, but not both, at a constant rate if an explanatory variable increases.\n",
    "\n",
    "Thus, linear regression assumes a linear model of price\n",
    "\n",
    "$$\\text{Price} = \\beta_0 + \\beta_1 \\text{Total Volume} + \\beta_2 \\text{Year} + \\beta_3 \\text{Month} + \\beta_4 \\text{Type}.$$\n",
    "\n",
    "In a linear regression model, we aim learn the coefficients, $\\beta_0 ,\\beta_1 ,\\beta_2 ,\\beta_3,\\beta_4$ that minimizes the mean squared error between the model and true response variables (prices). \n",
    "\n",
    "That is,\n",
    "$$\\min_{\\beta_0 ,\\beta_1 ,\\beta_2 ,\\beta_3,\\beta_4} \\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i - \\beta_0 + \\beta_1 \\text{Total Volume}_i + \\beta_2 \\text{Year}_i + \\beta_3 \\text{Month}_i + \\beta_4 \\text{Type}_i\\right)^2$$\n",
    "\n",
    "In learning a model, we will be to predict future prices and study how the explanatory variables affect price.\n",
    "    \n",
    "## 10.B Check Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we loaded the correct dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Observation 3272</th>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 8240</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 11769</th>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 1742</th>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 5981</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AveragePrice\n",
       "Observation 3272           1.01\n",
       "Observation 8240           1.48\n",
       "Observation 11769          1.63\n",
       "Observation 1742           0.70\n",
       "Observation 5981           0.67"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head of labels_training_set\n",
    "prices_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "      <th>...</th>\n",
       "      <th>region_StLouis</th>\n",
       "      <th>region_Syracuse</th>\n",
       "      <th>region_Tampa</th>\n",
       "      <th>region_TotalUS</th>\n",
       "      <th>region_West</th>\n",
       "      <th>region_WestTexNewMexico</th>\n",
       "      <th>type_organic</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Observation 3272</th>\n",
       "      <td>10.080124</td>\n",
       "      <td>13.205734</td>\n",
       "      <td>11.820667</td>\n",
       "      <td>7.783766</td>\n",
       "      <td>11.388065</td>\n",
       "      <td>13.584884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 8240</th>\n",
       "      <td>7.364737</td>\n",
       "      <td>10.693653</td>\n",
       "      <td>4.738389</td>\n",
       "      <td>7.641209</td>\n",
       "      <td>9.117004</td>\n",
       "      <td>10.971312</td>\n",
       "      <td>7.107425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 11769</th>\n",
       "      <td>6.669688</td>\n",
       "      <td>2.102914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.653338</td>\n",
       "      <td>7.974880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 1742</th>\n",
       "      <td>13.412152</td>\n",
       "      <td>12.080050</td>\n",
       "      <td>8.393972</td>\n",
       "      <td>9.991916</td>\n",
       "      <td>11.348697</td>\n",
       "      <td>13.770007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 5981</th>\n",
       "      <td>15.198407</td>\n",
       "      <td>15.082572</td>\n",
       "      <td>12.274380</td>\n",
       "      <td>8.966972</td>\n",
       "      <td>15.040339</td>\n",
       "      <td>16.232638</td>\n",
       "      <td>10.843619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        4046       4225       4770  Large Bags  Small Bags  \\\n",
       "Observation 3272   10.080124  13.205734  11.820667    7.783766   11.388065   \n",
       "Observation 8240    7.364737  10.693653   4.738389    7.641209    9.117004   \n",
       "Observation 11769   6.669688   2.102914   0.000000    0.000000    7.653338   \n",
       "Observation 1742   13.412152  12.080050   8.393972    9.991916   11.348697   \n",
       "Observation 5981   15.198407  15.082572  12.274380    8.966972   15.040339   \n",
       "\n",
       "                   Total Volume  XLarge Bags  Month_10  Month_11  Month_12  \\\n",
       "Observation 3272      13.584884     0.000000         0         0         0   \n",
       "Observation 8240      10.971312     7.107425         0         0         0   \n",
       "Observation 11769      7.974880     0.000000         0         0         0   \n",
       "Observation 1742      13.770007     0.000000         0         0         0   \n",
       "Observation 5981      16.232638    10.843619         0         0         0   \n",
       "\n",
       "                   ...  region_StLouis  region_Syracuse  region_Tampa  \\\n",
       "Observation 3272   ...               0                0             0   \n",
       "Observation 8240   ...               0                1             0   \n",
       "Observation 11769  ...               0                0             1   \n",
       "Observation 1742   ...               0                0             0   \n",
       "Observation 5981   ...               0                0             0   \n",
       "\n",
       "                   region_TotalUS  region_West  region_WestTexNewMexico  \\\n",
       "Observation 3272                0            0                        0   \n",
       "Observation 8240                0            0                        0   \n",
       "Observation 11769               0            0                        0   \n",
       "Observation 1742                0            0                        0   \n",
       "Observation 5981                0            0                        0   \n",
       "\n",
       "                   type_organic  year_2016  year_2017  year_2018  \n",
       "Observation 3272              0          1          0          0  \n",
       "Observation 8240              0          0          1          0  \n",
       "Observation 11769             1          0          0          0  \n",
       "Observation 1742              0          0          0          0  \n",
       "Observation 5981              0          0          1          0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head of  DNA_training_set\n",
    "\n",
    "avocado_training_set_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4046', '4225', '4770', 'Large Bags', 'Small Bags', 'Total Volume',\n",
       "       'XLarge Bags', 'Month_10', 'Month_11', 'Month_12', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'region_Atlanta', 'region_BaltimoreWashington', 'region_Boise',\n",
       "       'region_Boston', 'region_BuffaloRochester', 'region_California',\n",
       "       'region_Charlotte', 'region_Chicago', 'region_CincinnatiDayton',\n",
       "       'region_Columbus', 'region_DallasFtWorth', 'region_Denver',\n",
       "       'region_Detroit', 'region_GrandRapids', 'region_GreatLakes',\n",
       "       'region_HarrisburgScranton', 'region_HartfordSpringfield',\n",
       "       'region_Houston', 'region_Indianapolis', 'region_Jacksonville',\n",
       "       'region_LasVegas', 'region_LosAngeles', 'region_Louisville',\n",
       "       'region_MiamiFtLauderdale', 'region_Midsouth', 'region_Nashville',\n",
       "       'region_NewOrleansMobile', 'region_NewYork', 'region_Northeast',\n",
       "       'region_NorthernNewEngland', 'region_Orlando', 'region_Philadelphia',\n",
       "       'region_PhoenixTucson', 'region_Pittsburgh', 'region_Plains',\n",
       "       'region_Portland', 'region_RaleighGreensboro', 'region_RichmondNorfolk',\n",
       "       'region_Roanoke', 'region_Sacramento', 'region_SanDiego',\n",
       "       'region_SanFrancisco', 'region_Seattle', 'region_SouthCarolina',\n",
       "       'region_SouthCentral', 'region_Southeast', 'region_Spokane',\n",
       "       'region_StLouis', 'region_Syracuse', 'region_Tampa', 'region_TotalUS',\n",
       "       'region_West', 'region_WestTexNewMexico', 'type_organic', 'year_2016',\n",
       "       'year_2017', 'year_2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avocado_training_set_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.C Statistical Analysis\n",
    "\n",
    "In the avocado dataset, we have many explanatory variables. **How do we pick the explanatory variables that best explain the variation in the prices?**\n",
    "\n",
    "Interestingly, any random explanatory variable (as long as this variable is not colinear with another explanatory variable) will increase the $R^2$ value. Thus, increasing the accuracy of the dataset. However, this increase in accuracy may be insignificant. **How determine explanatory variables meaningfully reduce the error in the model?**\n",
    "\n",
    "Typically, one uses Anova and p-values of coefficients to choose to the ```best``` explanatory variable.\n",
    "\n",
    "*Neither does Scikit-learn allow for Anova to compare linear model nor does Scikit-learn  compute P values of coefficients of a linear model.* \n",
    "\n",
    "If you would like to do such statistical analysis, you need to use the ```statsmodels``` package. There maybe a workshop on this package in the summer.\n",
    "\n",
    "While Scikit cannot do such analysis, I argue that Anova and p-values are not the most effective ways of comparing linear models. \n",
    "\n",
    "- Anova depends on the order of term by term comparison\n",
    "- p-values of coefficients change depending other coefficients used in the model.\n",
    "\n",
    "## 10.D Overfitting\n",
    "\n",
    "It is important that we choose the most variables to put in the linear model. It is also important we do *overfit*. Overfitting is learning the training set too closely. \n",
    "\n",
    "Any sample population is not representative of the general population. Additionally, most data contain noise. A model that learns the training set to the T can reproduce behaviors that are mostly seen in the sample population.\n",
    "\n",
    "\n",
    "The test error is a heuristic used to measure fidelity to the general population. The test set is another sample of the general population that the model has not seen before. If the model performs poorly on the test set, then it is likely to perform poorly on the general population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.E.1 Model Selection: LASSO\n",
    "\n",
    "LASSO is a reformulation of the linear regression problem that removes coefficients that do not decrease the training error by a relatively large amount.\n",
    "\n",
    "Previously, we had the regression problem as: \n",
    "$$\\min_{\\beta_0 ,\\beta_1 ,\\beta_2 ,\\beta_3,\\beta_4} \\sum_{i=1}^{N}\\left(y_i - \\left(\\beta_0 + \\beta_1 \\text{Total Volume}_i + \\beta_2 \\text{Year}_i + \\beta_3 \\text{Month}_i + \\beta_4 \\text{Type}_i\\right)\\right)^2.$$\n",
    "\n",
    "LASSO reformulates the regression as:\n",
    "\n",
    "$$\\min_{\\beta_0 ,\\beta_1 ,\\beta_2 ,\\beta_3,\\beta_4} \\sum_{i=1}^{N}\\left(y_i - \\left(\\beta_0 + \\beta_1 \\text{Total Volume}_i + \\beta_2 \\text{Year}_i + \\beta_3 \\text{Month}_i + \\beta_4 \\text{Type}_i\\right)\\right)^2 + \\alpha \\sum_{j=1}^{4}|\\beta_j|.$$\n",
    "\n",
    "$\\alpha$ weighs eliminating non-zero coefficients against a decrease in training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.E.2 Building a linear model with ```Lasso```\n",
    "\n",
    "#### I. Initialize linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.01, fit_intercept=True, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Fitting linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "\n",
    "lasso.fit(explanatory_data,prices_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Getting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10142688, -0.        ,  0.12983296,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.51124165])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Interpretting model \n",
    "\n",
    "Our model is now \n",
    "\n",
    "$$\\text{Price} =2.5112 -0.1014\\times\\text{Total Demand} + 0.1298 \\times \\text{year_2017}.$$\n",
    "\n",
    "Note that our regression model without regularization was\n",
    "\n",
    "$$\\text{Price} = 2.5260 -0.1040 \\times \\text{Log(Total Demand)}-0.0106 \\times \\text{2016_year} + 0.1767\\times\\text{2017_year}+ 0.04261\\times\\text{2018_year}.$$\n",
    "\n",
    "We can interpret this reduction in our model as:\n",
    "\n",
    "\"*given $\\alpha=0.01$, $\\text{2016_year}$ and $\\text{2018_year}$ did not provide a large enough reduction in the training error to retain*.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V. Plotting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# predicted price\n",
    "predict_training_prices_ = lasso.predict(explanatory_data)\n",
    "\n",
    "# create index of variables that are 2017 and not 2017 \n",
    "year_2017 = avocado_training_set_cleaned['year_2017'].astype(bool)\n",
    "year_not_2017 = (year_2017 == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initialize plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "list_years = [year_not_2017,year_2017]\n",
    "years = [\"not 2017\",\"2017\"]\n",
    "colors = ['r','b']\n",
    "legend_name= []\n",
    "for i in range(len(list_years)):\n",
    "    indices = list_years[i]\n",
    "    # get data\n",
    "    training_total_volume_year_ = avocado_training_set_cleaned.loc[indices,\"Total Volume\"]\n",
    "    training_price_year_ = prices_training_set[indices]\n",
    "    predicted_training_prices_year = predict_training_prices_[indices]\n",
    "\n",
    "\n",
    "    # scatter plot of the demand \n",
    "    plt.scatter(training_total_volume_year_, training_price_year_ , s=5,\n",
    "                alpha=0.3,color=colors[i])\n",
    "    # plot of linear model \n",
    "    plt.plot(training_total_volume_year_, predicted_training_prices_year,c=colors[i])\n",
    "    legend_name.extend(['predicted model for ' + years[i], 'data for ' + years[i]])\n",
    "plt.xlabel('log(Total Volume)')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.E.3 Exercise: Building a linear model with ```Lasso``` with a small $\\alpha$\n",
    "\n",
    "Following the instructions above and the explanatory variables, ```['Total Volume','year_2016','year_2017', 'year_2018']```, build a linear model with Lasso and set ```alpha=1.0```. \n",
    "\n",
    "Print the coefficients of the linear model and compare these coefficients to those of the linear model without regularization:\n",
    "\n",
    "$$\\text{Price} = 2.5260 -0.1040 \\times \\text{Log(Total Demand)}-0.0106 \\times \\text{2016_year} + 0.1767\\times\\text{2017_year}+ 0.04261\\times\\text{2018_year}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0.  0. -0.]\n",
      "[1.40407155]\n"
     ]
    }
   ],
   "source": [
    "# enter solution here\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1.0, fit_intercept=True, normalize=False)\n",
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "lasso.fit(explanatory_data,prices_training_set)\n",
    "print(lasso.coef_)\n",
    "print(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.E.4 Exercise: Building a linear model with ```Lasso``` with a large $\\alpha$\n",
    "\n",
    "Following the instructions above and the explanatory variables, ```['Total Volume','year_2016','year_2017', 'year_2018']```, build a linear model with Lasso and set ```alpha= 1e-6```. \n",
    "\n",
    "Print the coefficients of the linear model and compare these coefficients to those of the linear model without regularization:\n",
    "\n",
    "$$\\text{Price} = 2.5260 -0.1040 \\times \\text{Log(Total Demand)}-0.0106 \\times \\text{2016_year} + 0.1767\\times\\text{2017_year}+ 0.04261\\times\\text{2018_year}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10400901 -0.01062718  0.17672741  0.04258284]\n",
      "[2.52603351]\n"
     ]
    }
   ],
   "source": [
    "# enter solution here\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=1e-6, fit_intercept=True, normalize=False)\n",
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "lasso.fit(explanatory_data,prices_training_set)\n",
    "print(lasso.coef_)\n",
    "print(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.F Choosing the best $\\alpha$\n",
    "\n",
    "Varying $\\alpha$ drastically affect the model we learn. Is there an alpha that most help us find the most effective model?\n",
    "\n",
    "## 10.F.1 Cross Validation\n",
    "\n",
    "\n",
    "Ideally, we would like to find an $\\alpha$ that minimizes model error in the general population.\n",
    "\n",
    "<img src=\"images/10_alpha_model_error.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "$\\alpha$ is a hyperparameter of machine learning model. A hyperparameter is value that must be set before learning begins.\n",
    "\n",
    "In machine learning, hyperparameters are learnt using *cross validation*. \n",
    "\n",
    "Cross validation is process by which a dataset into smaller datasets and hyperparameters that minimizes the average error on the sub-datasets are learn.\n",
    "\n",
    "\n",
    "## 10.F.2 Process of Cross Validation\n",
    "\n",
    "1) Divide the dataset into *folds*. Folds are smaller datasets of a larger dataset.\n",
    "\n",
    "<img src=\"images/10_folds.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "2) Set the hyperparameter to an intelligent guess.\n",
    "\n",
    "3) A fold is then removed and, given the hyperparameter above, the model is trained on the remaining folds.\n",
    "\n",
    "<img src=\"images/10_cross_validation.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "4) Repeat step 3 repeat until each fold as been removed at least once.\n",
    "\n",
    "5) Vary the hyperparameter.\n",
    "\n",
    "6) Repeat Steps 3-4.\n",
    "\n",
    "7) Repeat steps 5-6 until varying hyperparameter always leads to an increase in model error.\n",
    "\n",
    "**Note: If you divide your dataset into $k$ folds, the cross validation is called *k-fold cross validation*.**\n",
    "\n",
    "**If you divide your dataset so that each fold contains one data point, the cross validation is called *leave-one-out cross validation*.**\n",
    "\n",
    "\n",
    "## 10.F.3 Cross Validation in Scikit-Learn\n",
    "\n",
    "To do a hyperparameter search using the cross validation, we use the ```GridSearchCV``` class. It takes as argument:\n",
    "- the estimator object you are using\n",
    "- the hyperparameter points to check\n",
    "- the scoring method used, for example mean squared error\n",
    "- the number of folds\n",
    "\n",
    "#### I. Initialize ```GridSearchCV```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "lasso = Lasso()\n",
    "# set parameter grid\n",
    "param_grid = {'alpha' : [1.0,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9]}\n",
    "\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, scoring='neg_mean_squared_error',cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Learn best hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "lasso_cv.fit(explanatory_data,prices_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "best_params_ = lasso_cv.best_params_\n",
    "print(best_params_)\n",
    "best_alpha=best_params_['alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Retrain Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10400579 -0.01062989  0.17666686  0.04242664]\n",
      "[2.52602822]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=best_alpha, fit_intercept=True, normalize=False)\n",
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "lasso.fit(explanatory_data,prices_training_set)\n",
    "print(lasso.coef_)\n",
    "print(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the choice of variables ```'Total Volume','year_2016', 'year_2017', 'year_2018'```, ```LASSO``` finds the best model to be\n",
    "\n",
    "$$\\text{Price} = 2.6749 -0.122 \\times \\text{Log(Total Demand)}-0.0027 \\times \\text{2016_year} + 0.1988\\times\\text{2017_year}+  0.0481\\times\\text{2018_year}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.F.4 Exercise: Cross Validation with LassoCV.\n",
    "\n",
    "Using Lasso with cross validation is so common that scikit-learn created a class for it! It is alot simplier than using ```GridSearchCV```. \n",
    "\n",
    "With the explanatory variables, ['Total Volume','year_2016','year_2017', 'year_2018'], and response variable, ```prices_training_set```, follow the steps below use ```LassoCV```.\n",
    "\n",
    "\n",
    "#### I. Initialize\n",
    "\n",
    "First, you need to initialize ```LassoCV```. It takes argments:\n",
    "\n",
    "- ```alphas``` - a list of alphas\n",
    "- ```cv``` - the number of folds.\n",
    "\n",
    "I set the values of arguments below. ```LassoCV``` computes the mean squared error on the remaining folds.\n",
    "\n",
    "#### II. Fitting \n",
    "\n",
    "Next, you need to fit your instance of ```LassoCV``` to the training data. Use ```explanatory_data``` and ```training_response``` to fit your model.\n",
    "\n",
    "#### III. Get best alpha\n",
    "\n",
    "After getting the best fitting your instance, ```LassoCV``` stores the best alpha as ```alpha_```. Get the best alpha and store it as ```best_alpha.``` Print the best alpha.\n",
    "\n",
    "#### IV. Get model parameters\n",
    "\n",
    "```LassoCV``` also refits ```Lasso``` to the model explanatory data using the best alpha found above. It stores the coefficients, ```coef_``` and ```intercept_```, of Lasso with best alpha. Print these coefficients and interpret associated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanatory variables\n",
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "\n",
    "training_response = prices_training_set.values.ravel()\n",
    "# reformat prices \n",
    "# load LassoCV\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "import numpy as np\n",
    "# set LassoCV arguments\n",
    "alpha_list = np.logspace(0,-9,num=10) # list of alphas\n",
    "k = 10 # number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution for I here\n",
    "# initialize LassoCV\n",
    "\n",
    "lasso_cv = LassoCV(alphas=alpha_list,cv = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,\n",
       "       1.e-08, 1.e-09]),\n",
       "    copy_X=True, cv=10, eps=0.001, fit_intercept=True, max_iter=1000,\n",
       "    n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter solution for II here\n",
    "# fit LassoCV\n",
    "\n",
    "lasso_cv.fit(explanatory_data,training_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "# enter solution for III here\n",
    "# get best alpha\n",
    "best_alpha = lasso_cv.alpha_\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10400579, -0.01062989,  0.17666686,  0.04242664])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter solution for IV here\n",
    "# get best alpha\n",
    "lasso_cv.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.F.5 Exercise: Cross Validation with LassoCV.\n",
    "\n",
    "Repeat the steps in the exercise above to find the best alpha with the explanatory variables, ['Total Volume','type_organic','year_2016','year_2017', 'year_2018'], and response variable, ```prices_training_set```.\n",
    "\n",
    "Train ```Lasso``` with the best alpha found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanatory variables\n",
    "explanatory_data= avocado_training_set_cleaned[['Total Volume','type_organic','year_2016',\n",
    "                                                'year_2017', 'year_2018']]\n",
    "\n",
    "training_response = prices_training_set.values.ravel()\n",
    "# reformat prices \n",
    "# load LassoCV\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "# set LassoCV arguments\n",
    "\n",
    "import numpy as np\n",
    "alpha_list=np.logspace(0,-9,num=20)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016237767391887227\n"
     ]
    }
   ],
   "source": [
    "# enter solution here to train LassoCV\n",
    "\n",
    "# initialize LassoCV\n",
    "lasso_cv = LassoCV(alphas=alpha_list,cv = k)\n",
    "# fit LassoCV\n",
    "lasso_cv.fit(explanatory_data,training_response)\n",
    "# get best alpha\n",
    "best_alpha = lasso_cv.alpha_\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04790003  0.32038406 -0.02728927  0.15117733  0.        ]\n",
      "1.7465145138413196\n"
     ]
    }
   ],
   "source": [
    "print(lasso_cv.coef_)\n",
    "print(lasso_cv.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the choice of variables ```'Total Volume','type_organic','year_2016', 'year_2017', 'year_2018',``` LASSO finds the best model to be```LASSO``` finds the best model to be\n",
    "\n",
    "$$\\text{Price} = 1.7465 -0.0479 \\times \\text{Log(Total Demand)} + 0.3203\\times\\text{type_organic}-0.0272 \\times \\text{2016_year} +0.1511\\times\\text{2017_year}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
