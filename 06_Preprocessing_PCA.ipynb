{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Review\n",
    "## 0.A Scikit-Learn\n",
    "\n",
    "Scikit-Learn is a machine learning python package. It allows users to access machine learning algorithms via **object-oriented programming**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.B Data Set\n",
    "\n",
    "I will be using a dataset of antibiotic resistance in bacteria strains. \n",
    "\n",
    "- Each bacteria is labeled with its resistance to the antibiotic, azithromycin.\n",
    "- Additionally, each bacteria sample is labelled if its genome contains certain strands of DNA.\n",
    "\n",
    "We would like to learn antibiotic resistance from the bacterial genome. \n",
    "\n",
    "- Our predictors are whether strands of DNA are present.\n",
    "- Our response are resistance classes.\n",
    "\n",
    "First, we have to clean our data up. **This section will focus on data preprocessing.**\n",
    "\n",
    "\n",
    "## 0.C Data Preprocessing\n",
    "\n",
    "We did a bit of data preprocessing: \n",
    "\n",
    "- encoded the resistance feature as 0 - \"resistant,\" 1 - \"susceptible\".\n",
    "- encoded all features of the DNA strands as, 0 - \"if its genome does not contain the strand of DNA\", 1 - \"if its genome contains the strand of DNA.\"\n",
    "- did a 70:30 training-test split\n",
    "\n",
    "## 0.D Load Data\n",
    "Now, we load our dataset. Run the code below to load \n",
    "\n",
    "- the dataset, ```antibiotic_resistance_all_labels```, containing antibotic resistance phentype for each bacteria\n",
    "- and dataset, ```DNA_slices_all_df```, containing the genome of each bacteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "antibiotic_resistance_all_labels = pd.read_csv('datasets/antibiotic_resistance_encoded_labels',index_col=0)\n",
    "DNA_slices_all_df = pd.read_csv('datasets/DNA_slices_encoded_csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section, we will be learning about normalization and standardization preprocessing. This is important for many unsupervised ML algorithms that are sensitive to the scales in the variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Normalization\n",
    "\n",
    "Normalization rescales quantitative variables to be between $0$ and $1$. Normalizing allows for comparison of columns.\n",
    "\n",
    "For each variable, normalizing subtracts the minimium value and divides by the difference between the maximum and minimum. \n",
    "\n",
    "\n",
    "## 6.A Example\n",
    "\n",
    "Let's digress a little from the k-mer dataset and let's consider the dataset of weight and weight,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 120 | 177 |\n",
    "| **Observation 2** | 200 | 100 |\n",
    "| **Observation 3** | 150 | 155 |\n",
    "| **Observation 4** | 172 | 125 |\n",
    "\n",
    "Let's normalize the weight column. First, we substract the minimum, $120$, and then divide by the difference between the maximum and minimum, $200-120$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | (120-120)/(200 - 120) | 177 |\n",
    "| **Observation 2** | (200-120)/(200 - 120) | 100 |\n",
    "| **Observation 3** | (150-120)/(200 - 120) | 155 |\n",
    "| **Observation 4** | (172-120)/(200 - 120) | 125 |\n",
    "\n",
    "Let's normalize the height column. First, again, we substract the minimum, $100$, and then divide by the difference between the maximum and minimum, $177-100$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0 | (177-100)/(177-100)|\n",
    "| **Observation 2** | 1 | (100-100)/(177-100) |\n",
    "| **Observation 3** | 0.375 | (155-100)/(177-100) |\n",
    "| **Observation 4** | 0.65 | (125-100)/(177-100) |\n",
    "\n",
    "Our final normalized dataset is then, \n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0 | 1 |\n",
    "| **Observation 2** | 1 | 0 |\n",
    "| **Observation 3** | 0.375 | 0.71 |\n",
    "| **Observation 4** | 0.65 | 0.32 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.B Normalization with scikit-learn\n",
    "\n",
    "### 6.B.1 Normalizing body measurements dataframe\n",
    "\n",
    "Now, we will normalize the same data set of the measurements with scikit-learn. We will then compare our calculations with the results of the scikit-learn.  \n",
    "\n",
    "Below, I create a pandas dataframe of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = {'Weight': [120.0, 200.0, 150.0, 172.0],\n",
    "        'Height': [177.0, 100.0, 155.0, 125.0]}\n",
    "\n",
    "bd_measurements_df = pd.DataFrame(data, \n",
    "             index=[\"Observation 1\",\"Observation 2\", \"Observation 3\", \"Observation 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print dataframe bd_measurements_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Initialize MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the class that normalizes the data is ```MinMaxScaler```, not ```Normalizer```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# initialize MinMaxScaler() as scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Train MinMaxScaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```fit``` method, we train our ```MinMaxScaler()``` instance on how to scale our data. We do this on the weight column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store bd_measurements_df['Weight'] as weight_column\n",
    "\n",
    "# print weight_column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array using .values.reshape(-1,1)\n",
    "# i.e. weight_column = weight_column.values.reshape(-1,1)\n",
    "\n",
    "#print new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler with weight column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.transform transform weight_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```MinMaxScaler()``` object learn the parameters, minimum, maximum and range of the data, to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data minimum, data_min_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data max, data_max_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data range, data_range_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.2 Exercise: Normalizing the height column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the steps above normalize ```height_column``` and compare it to the results calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_column = bd_measurements_df['Height'].values.reshape(-1,1)\n",
    "height_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n",
    "\n",
    "# fit data\n",
    "\n",
    "\n",
    "# then transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.3 ```fit_transform```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a convience function, ```fit_transform```, which fit the Normalizer and transform the data in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use fit_transform on  height_column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.4 Drawbacks of Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization has two main issues: \n",
    "- the values it returns aren't easily interpretable\n",
    "- it's sensitive to outliers.\n",
    "    \n",
    "Consider the data set,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 150 | 200 |\n",
    "| **Observation 2** | 1000 | 10240 |\n",
    "| **Observation 3** | 20000 | 10000 |\n",
    "| **Observation 4** | 1021 | 10020 |\n",
    "\n",
    "Normalization returns the data set, \n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0.00 | 0 |\n",
    "| **Observation 2** | 0.04 | 1.00 |\n",
    "| **Observation 3** | 1.00 | 0.98 |\n",
    "| **Observation 4** | 0.04 | 0.98 |\n",
    "\n",
    "With outliers, it is possible that the data can either be squashed around 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization overcomes these drawbacks of normalization. \n",
    "\n",
    "Standardization rescales variables so that the variables are measured by the number of standard deviations away from the mean.\n",
    "\n",
    "From each column, standardization substracts its mean and divides the column entries by its standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.A Example\n",
    "\n",
    "Let's consider the dataset of height and weight,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 150 | 200 |\n",
    "| **Observation 2** | 1000 | 10240 |\n",
    "| **Observation 3** | 20000 | 10000 |\n",
    "| **Observation 4** | 1021 | 10020 |\n",
    "\n",
    "Let's standardize the weight column. First, we substract the mean, $5542.75$, and then divide by the standard deviation, $8354$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | (150-5542.75)/8354 | 200 |\n",
    "| **Observation 2** | (1000-5542.75)/8354 | 10240 |\n",
    "| **Observation 3** | (20000-5542.75)/8354 | 10000 |\n",
    "| **Observation 4** | (1021-5542.75)/8354 | 10020 |\n",
    "\n",
    "Let's standardize the height column. First, we substract the mean, $7615$, and then divide by the standard deviation, $4282$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | -0.64 | (200-7615)/4282 |\n",
    "| **Observation 2** | -0.54 | (10240-7615)/4282 |\n",
    "| **Observation 3** | 1.73 | (10000-7615)/4282 |\n",
    "| **Observation 4** | -0.54 | (10020-7615)/4282 |\n",
    "\n",
    "Our final normalized dataset is then, \n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | -0.64 | -1.73 |\n",
    "| **Observation 2** | -0.54 | 0.61 |\n",
    "| **Observation 3** | 1.73 | 0.56 |\n",
    "| **Observation 4** | -0.54 | 0.56 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.B Standardization with scikit-learn\n",
    "\n",
    "### 6.B.1 Standardizing body measurements dataframe\n",
    "\n",
    "Now, we will standardize the same data set of the measurements with scikit-learn. We will then compare our calculations with the results of the scikit-learn.  \n",
    "\n",
    "Below, I create a pandas dataframe of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = {'Weight': [150.0, 1000.0, 20000.0, 1021.0],\n",
    "        'Height': [200.0, 10240.0, 10000.0,10020.0]}\n",
    "\n",
    "bd_measurements_df = pd.DataFrame(data, \n",
    "             index=[\"Observation 1\",\"Observation 2\", \"Observation 3\", \"Observation 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataframe, bd_measurements_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Initialize ```StandardScaler()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#initialize StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Train StandardScaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```fit``` method, we train our ```StandardScaler()``` instance on how to scale our data. We do this on the weight column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bd_measurements_df['Weight'] to numpy array and reshape using .values.reshape(-1, 1)\n",
    "# store in weight_column\n",
    "\n",
    "\n",
    "# fit to scaler object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data using scaler.transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```MinMaxScaler()``` object learn the parameters, mean, maximum and range of the data, to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data mean, mean_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data scale, scale_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.2 Exercise: Standardizing the height column\n",
    "\n",
    "Following the steps above normalize ```height_column``` and compare it to the results calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_column = bd_measurements_df['Height'].values.reshape(-1, 1)\n",
    "height_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n",
    "\n",
    "# fit to data\n",
    "\n",
    "\n",
    "# transform data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B.3 ```fit_transform```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a convience function, ```fit_transform```, which fit the ```StandardScaler``` and transform the data in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit_transfrom on height_column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.4 Exercise: Standardizing the DNA_ column\n",
    "\n",
    "Now let's move back to k-mer dataset! \n",
    "\n",
    "\n",
    "Following the steps above standardize ```DNA_slices_all_df```. Store the standardized array as ```standardized_DNA_data```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# initialize StandardScaler object\n",
    "\n",
    "# fit StandardScaler object to data and then transform data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the output back to a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_DNA_data_df = pd.DataFrame(standardized_DNA_data,\n",
    "                                        columns=DNA_slices_all_df.columns,\n",
    "                                        index=DNA_slices_all_df.index)\n",
    "standardized_DNA_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
