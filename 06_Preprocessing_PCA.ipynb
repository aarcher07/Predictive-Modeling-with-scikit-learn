{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Review\n",
    "## 0.A Scikit-Learn\n",
    "\n",
    "Scikit-Learn is a machine learning python package. It allows users to access machine learning algorithms via **object-oriented programming**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.B Data Set\n",
    "\n",
    "I will be using a dataset of antibiotic resistance in bacteria strains. \n",
    "\n",
    "- Each bacteria is labeled with its resistance to the antibiotic, azithromycin.\n",
    "- Additionally, each bacteria sample is labelled if its genome contains certain strands of DNA.\n",
    "\n",
    "We would like to learn antibiotic resistance from the bacterial genome. \n",
    "\n",
    "- Our predictors are whether strands of DNA are present.\n",
    "- Our response are resistance classes.\n",
    "\n",
    "First, we have to clean our data up. **This section will focus on data preprocessing.**\n",
    "\n",
    "\n",
    "## 0.C Data Preprocessing\n",
    "\n",
    "We did a bit of data preprocessing: \n",
    "\n",
    "- encoded the resistance feature as 0 - \"resistant,\" 1 - \"susceptible\".\n",
    "- encoded all features of the DNA strands as, 0 - \"if its genome does not contain the strand of DNA\", 1 - \"if its genome contains the strand of DNA.\"\n",
    "- did a 70:30 training-test split\n",
    "\n",
    "## 0.D Load Data\n",
    "Now, we load our dataset. Run the code below to load \n",
    "\n",
    "- the dataset, ```antibiotic_resistance_all_labels```, containing antibotic resistance phentype for each bacteria\n",
    "- and dataset, ```DNA_slices_all_df```, containing the genome of each bacteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "antibiotic_resistance_all_labels = pd.read_csv('datasets/antibiotic_resistance_encoded_labels',index_col=0)\n",
    "DNA_slices_all_df = pd.read_csv('datasets/DNA_slices_encoded_csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section, we will be learning about normalization and standardization preprocessing. This is important for many unsupervised ML algorithms that are sensitive to the scales in the variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Normalization\n",
    "\n",
    "Normalization rescales quantitative variables to be between $0$ and $1$. Normalizing allows for comparison of columns.\n",
    "\n",
    "For each variable, normalizing subtracts the minimium value and divides by the difference between the maximum and minimum. \n",
    "\n",
    "\n",
    "## 6.A Example\n",
    "\n",
    "Let's digress a little from the k-mer dataset and let's consider the dataset of weight and weight,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 120 | 177 |\n",
    "| **Observation 2** | 200 | 100 |\n",
    "| **Observation 3** | 150 | 155 |\n",
    "| **Observation 4** | 172 | 125 |\n",
    "\n",
    "Let's normalize the weight column. First, we substract the minimum, $120$, and then divide by the difference between the maximum and minimum, $200-120$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | (120-120)/(200 - 120) | 177 |\n",
    "| **Observation 2** | (200-120)/(200 - 120) | 100 |\n",
    "| **Observation 3** | (150-120)/(200 - 120) | 155 |\n",
    "| **Observation 4** | (172-120)/(200 - 120) | 125 |\n",
    "\n",
    "Let's normalize the height column. First, again, we substract the minimum, $100$, and then divide by the difference between the maximum and minimum, $177-100$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0 | (177-100)/(177-100)|\n",
    "| **Observation 2** | 1 | (100-100)/(177-100) |\n",
    "| **Observation 3** | 0.375 | (155-100)/(177-100) |\n",
    "| **Observation 4** | 0.65 | (125-100)/(177-100) |\n",
    "\n",
    "Our final normalized dataset is then, \n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0 | 1 |\n",
    "| **Observation 2** | 1 | 0 |\n",
    "| **Observation 3** | 0.375 | 0.71 |\n",
    "| **Observation 4** | 0.65 | 0.32 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.B Normalization with scikit-learn\n",
    "\n",
    "### 6.B.1 Normalizing body measurements dataframe\n",
    "\n",
    "Now, we will normalize the same data set of the measurements with scikit-learn. We will then compare our calculations with the results of the scikit-learn.  \n",
    "\n",
    "Below, I create a pandas dataframe of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = {'Weight': [120.0, 200.0, 150.0, 172.0],\n",
    "        'Height': [177.0, 100.0, 155.0, 125.0]}\n",
    "\n",
    "bd_measurements_df = pd.DataFrame(data, \n",
    "             index=[\"Observation 1\",\"Observation 2\", \"Observation 3\", \"Observation 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Observation 1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 4</th>\n",
       "      <td>172.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Weight  Height\n",
       "Observation 1   120.0   177.0\n",
       "Observation 2   200.0   100.0\n",
       "Observation 3   150.0   155.0\n",
       "Observation 4   172.0   125.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_measurements_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Initialize MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the class that normalizes the data is ```MinMaxScaler```, not ```Normalizer```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Train MinMaxScaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```fit``` method, we train our ```MinMaxScaler()``` instance on how to scale our data. We do this on the weight column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Observation 1    120.0\n",
       "Observation 2    200.0\n",
       "Observation 3    150.0\n",
       "Observation 4    172.0\n",
       "Name: Weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_column = bd_measurements_df['Weight']\n",
    "weight_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120., 200., 150., 172.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_column = bd_measurements_df['Weight'].to_numpy()\n",
    "weight_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120.],\n",
       "       [200.],\n",
       "       [150.],\n",
       "       [172.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_column = bd_measurements_df['Weight'].to_numpy().reshape(-1, 1)\n",
    "weight_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(weight_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   ],\n",
       "       [1.   ],\n",
       "       [0.375],\n",
       "       [0.65 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(weight_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```MinMaxScaler()``` object learn the parameters, minimum, maximum and range of the data, to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data minimum\n",
    "scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data maximum\n",
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data range\n",
    "scaler.data_range_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.2 Exercise: Normalizing the height column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the steps above normalize ```height_column``` and compare it to the results calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_column = bd_measurements_df['Height'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.        ],\n",
       "       [0.71428571],\n",
       "       [0.32467532]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter solution here\n",
    "scaler.fit(height_column)\n",
    "scaler.transform(height_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.3 ```fit_transform```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a convience function, ```fit_transform```, which fit the Normalizer and transform the data in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.        ],\n",
       "       [0.71428571],\n",
       "       [0.32467532]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(height_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.4 Drawbacks of Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization has two main issues: \n",
    "- the values it returns aren't easily interpretable\n",
    "- it's sensitive to outliers.\n",
    "    \n",
    "Consider the data set,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 150 | 200 |\n",
    "| **Observation 2** | 1000 | 10240 |\n",
    "| **Observation 3** | 20000 | 10000 |\n",
    "| **Observation 4** | 1021 | 10020 |\n",
    "\n",
    "Normalization returns the data set, \n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 0.00 | 0 |\n",
    "| **Observation 2** | 0.04 | 1.00 |\n",
    "| **Observation 3** | 1.00 | 0.98 |\n",
    "| **Observation 4** | 0.04 | 0.98 |\n",
    "\n",
    "With outliers, it is possible that the data can either be squashed around 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization overcomes these drawbacks of normalization. \n",
    "\n",
    "Standardization rescales variables so that the variables are measured by the number of standard deviations away from the mean.\n",
    "\n",
    "From each column, standardization substracts its mean and divides the column entries by its standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.A Example\n",
    "\n",
    "Let's consider the dataset of height and weight,\n",
    "\n",
    "| . | Weight/pounds | Height/cm |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | 150 | 200 |\n",
    "| **Observation 2** | 1000 | 10240 |\n",
    "| **Observation 3** | 20000 | 10000 |\n",
    "| **Observation 4** | 1021 | 10020 |\n",
    "\n",
    "Let's standardize the weight column. First, we substract the mean, $5542.75$, and then divide by the standard deviation, $8354$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | (150-5542.75)/8354 | 200 |\n",
    "| **Observation 2** | (1000-5542.75)/8354 | 10240 |\n",
    "| **Observation 3** | (20000-5542.75)/8354 | 10000 |\n",
    "| **Observation 4** | (1021-5542.75)/8354 | 10020 |\n",
    "\n",
    "Let's standardize the height column. First, we substract the mean, $7615$, and then divide by the standard deviation, $4282$.\n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | -0.64 | (200-7615)/4282 |\n",
    "| **Observation 2** | -0.54 | (10240-7615)/4282 |\n",
    "| **Observation 3** | 1.73 | (10000-7615)/4282 |\n",
    "| **Observation 4** | -0.54 | (10020-7615)/4282 |\n",
    "\n",
    "Our final normalized dataset is then, \n",
    "\n",
    "\n",
    "| . | Weight | Height |\n",
    "| --- | --- | --- |\n",
    "| **Observation 1** | -0.64 | -1.73 |\n",
    "| **Observation 2** | -0.54 | 0.61 |\n",
    "| **Observation 3** | 1.73 | 0.56 |\n",
    "| **Observation 4** | -0.54 | 0.56 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.B Standardization with scikit-learn\n",
    "\n",
    "### 6.B.1 Standardizing body measurements dataframe\n",
    "\n",
    "Now, we will standardize the same data set of the measurements with scikit-learn. We will then compare our calculations with the results of the scikit-learn.  \n",
    "\n",
    "Below, I create a pandas dataframe of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = {'Weight': [150.0, 1000.0, 20000.0, 1021.0],\n",
    "        'Height': [200.0, 10240.0, 10000.0,10020.0]}\n",
    "\n",
    "bd_measurements_df = pd.DataFrame(data, \n",
    "             index=[\"Observation 1\",\"Observation 2\", \"Observation 3\", \"Observation 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Observation 1</th>\n",
       "      <td>150.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>10240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observation 4</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>10020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Weight   Height\n",
       "Observation 1    150.0    200.0\n",
       "Observation 2   1000.0  10240.0\n",
       "Observation 3  20000.0  10000.0\n",
       "Observation 4   1021.0  10020.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_measurements_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Initialize ```StandardScaler()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Train StandardScaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```fit``` method, we train our ```StandardScaler()``` instance on how to scale our data. We do this on the weight column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_column = bd_measurements_df['Weight'].to_numpy().reshape(-1, 1)\n",
    "scaler.fit(weight_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6455067 ],\n",
       "       [-0.54376256],\n",
       "       [ 1.73051814],\n",
       "       [-0.54124888]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(weight_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```MinMaxScaler()``` object learn the parameters, mean, maximum and range of the data, to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5542.75])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data mean\n",
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8354.28977756])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data scale\n",
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.2 Exercise: Standardizing the height column\n",
    "\n",
    "Following the steps above normalize ```height_column``` and compare it to the results calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_column = bd_measurements_df['Height'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73163198],\n",
       "       [ 0.61301874],\n",
       "       [ 0.55697131],\n",
       "       [ 0.56164193]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter solution here\n",
    "scaler.fit(height_column)\n",
    "scaler.transform(height_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B.3 ```fit_transform```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a convience function, ```fit_transform```, which fit the ```StandardScaler``` and transform the data in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73163198],\n",
       "       [ 0.61301874],\n",
       "       [ 0.55697131],\n",
       "       [ 0.56164193]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(height_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B.4 Exercise: Standardizing the DNA_ column\n",
    "\n",
    "Now let's move back to k-mer dataset! \n",
    "\n",
    "\n",
    "Following the steps above standardize ```DNA_slices_all_df```. Store the standardized array as ```standardized_DNA_data```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter solution here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "standardized_DNA_data = scaler.fit_transform(DNA_slices_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the output back to a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmerlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d52c56e37c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         index=DNA_slices_all_df.index)\n\u001b[1;32m      4\u001b[0m \u001b[0mstandardized_DNA_data_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstandardized_DNA_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/standardized_DNA_data_df\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkmerlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kmerlist' is not defined"
     ]
    }
   ],
   "source": [
    "standardized_DNA_data_df = pd.DataFrame(standardized_DNA_data,\n",
    "                                        columns=DNA_slices_all_df.columns,\n",
    "                                        index=DNA_slices_all_df.index)\n",
    "standardized_DNA_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
